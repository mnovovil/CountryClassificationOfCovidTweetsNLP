{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rand\n",
    "import pandas as pd\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Thomas\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (2,3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "training_df = pd.read_csv(\"C:\\\\Users\\\\Thomas\\\\Desktop\\\\training_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>reply_to_screen_name</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Remember the #WuhanCoronaVirus? The pandemic w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>WuhanCoronaVirus KillerCuomo</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My sources @WhiteHouse say 2 tactics will be u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Trump</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'll venture a wild guess: If you were running...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>COVID19</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Pakistan (#GreenStimulus = #Nature protection...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Pakistan GreenStimulus Nature Green</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üá∫üá∏ Pand√©mie de #coronavirus: 30 pasteurs am√©ri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>coronavirus COVID__19 COVID„Éº19</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>So I made a meme....#corona #virus #meme #coro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>corona virus meme coronavirusmeme toilet paper...</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>When I first saw the revised CDC figure‚Äîwhich ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Coronavirus</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Um, no one‚Äôs really listening to you. #blackli...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>blacklifematters COVID19 StopPoliceBrutality</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>‡ÆÜ‡Æï‡Øç‡Æï‡Æ™‡Øç‡Æ™‡ØÇ‡Æ∞‡Øç‡Æµ‡ÆÆ‡Ææ‡Æ© ‡ÆØ‡Øã‡Æö‡Æ©‡Øà‡ÆØ‡Øà @CMOTamilNadu ‡ÆÖ‡Æ∞‡Æö‡ØÅ‡Æï‡Øç‡Æï‡ØÅ ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>corona</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Academy Might Be Postponing The Oscars\\n\\n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>TheAcademy AcademyAwards Oscars TheOscars AMPA...</td>\n",
       "      <td>us</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text reply_to_screen_name  \\\n",
       "0  Remember the #WuhanCoronaVirus? The pandemic w...                  NaN   \n",
       "1  My sources @WhiteHouse say 2 tactics will be u...                  NaN   \n",
       "2  I'll venture a wild guess: If you were running...                  NaN   \n",
       "3  #Pakistan (#GreenStimulus = #Nature protection...                  NaN   \n",
       "4  üá∫üá∏ Pand√©mie de #coronavirus: 30 pasteurs am√©ri...                  NaN   \n",
       "5  So I made a meme....#corona #virus #meme #coro...                  NaN   \n",
       "6  When I first saw the revised CDC figure‚Äîwhich ...                  NaN   \n",
       "7  Um, no one‚Äôs really listening to you. #blackli...                  NaN   \n",
       "8  ‡ÆÜ‡Æï‡Øç‡Æï‡Æ™‡Øç‡Æ™‡ØÇ‡Æ∞‡Øç‡Æµ‡ÆÆ‡Ææ‡Æ© ‡ÆØ‡Øã‡Æö‡Æ©‡Øà‡ÆØ‡Øà @CMOTamilNadu ‡ÆÖ‡Æ∞‡Æö‡ØÅ‡Æï‡Øç‡Æï‡ØÅ ...                  NaN   \n",
       "9  The Academy Might Be Postponing The Oscars\\n\\n...                  NaN   \n",
       "\n",
       "  is_quote is_retweet                                           hashtags  \\\n",
       "0    False       True                       WuhanCoronaVirus KillerCuomo   \n",
       "1    False       True                                              Trump   \n",
       "2    False       True                                            COVID19   \n",
       "3    False       True                Pakistan GreenStimulus Nature Green   \n",
       "4    False       True                     coronavirus COVID__19 COVID„Éº19   \n",
       "5    False       True  corona virus meme coronavirusmeme toilet paper...   \n",
       "6    False       True                                        Coronavirus   \n",
       "7     True      False       blacklifematters COVID19 StopPoliceBrutality   \n",
       "8    False       True                                             corona   \n",
       "9    False      False  TheAcademy AcademyAwards Oscars TheOscars AMPA...   \n",
       "\n",
       "  country  \n",
       "0      us  \n",
       "1      us  \n",
       "2      us  \n",
       "3      us  \n",
       "4      us  \n",
       "5      us  \n",
       "6      us  \n",
       "7      us  \n",
       "8      us  \n",
       "9      us  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_df['text_remove_newline'] = training_df['text'].apply(lambda x: x.replace(\"\\n\", \"\"))\n",
    "#training_df['text_demojize'] = training_df['text_remove_newline'].apply(lambda x: emoji.demojize(x, delimiters=(\"\", \" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "session = requests.Session()\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowlist = [\n",
    "  'p',\n",
    "  'h1',\n",
    "  'h2',\n",
    "  'div',\n",
    "]\n",
    "\n",
    "#expanding URLs\n",
    "def get_URL_data(tweet):\n",
    "\turls = re.findall(r'(https?://\\S+)', tweet)\n",
    "\tfor url in urls:\n",
    "\t\ttry:\n",
    "\t\t\ttweet = tweet.replace(url, session.head(url, allow_redirects=True, timeout=3).url)\n",
    "\t\t\t\n",
    "\t\t\t#html = requests.get(url).text\n",
    "\t\t\t#print(html)\n",
    "\t\t\t#soup = BeautifulSoup(html, \"lxml\")\n",
    "\t\t\t#text_elements = [t for t in soup.find_all(text=True) if t.parent.name in allowlist]\n",
    "\t\t\t#text += \" \".join(text_elements)\n",
    "\t\texcept:\n",
    "\t\t\tcontinue\n",
    "\t\n",
    "\t#text = text.replace(\"\\n\", \"\")\n",
    "\t#text = text.replace(\"\\t\", \"\")\n",
    "\t#text = \" \".join(text.split())\n",
    "\t#data = [tweet, text]\n",
    "\t\n",
    "\treturn tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'So remember Sturgis rally...?\\nPositives are rolling in.\\n#COVID19\\nhttps://www.google.com/amp/s/www.cbsnews.com/amp/news/coronavirus-sturgis-motorcycle-rally-south-dakota-over-100-cases-8-states/'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_URL_data(training_df['text'][21495])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2088/240000 [18:32<17:30:11,  3.78it/s] "
     ]
    }
   ],
   "source": [
    "data = []\n",
    "file_cnt = 1\n",
    "for i in tqdm(range(len(training_df))):\n",
    "\tdata.append(get_URL_data(training_df['text'][i]))\n",
    "\t\n",
    "\tif (i % 5000 == 0 and i != 0):\n",
    "\t\tdf = pd.DataFrame(data, columns = ['text_full_url'])\n",
    "\t\tdf.to_csv('data/training_data2_' + str(file_cnt) + '.csv', index = False)\n",
    "\t\tdata = []\n",
    "\t\tfile_cnt += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translate emoji to words\n",
    "training_df['text_full_url'] = training_df['text_full_url'].apply(lambda x: emoji.demojize(x, delimiters = (\" \", \" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = training_df['country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "X_vec = tfidf.fit_transform(training_df['text_full_url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_560/1034011083.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_vec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_vec' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_vec,y,test_size=0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.447875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "y_pred = nb.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44997916666666665\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm = LinearSVC()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "lr = LogisticRegression(solver = 'saga')\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d8cf412c429d163f0ec8962de5d99a5f7520d1b1380235674c38dc96da666cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
